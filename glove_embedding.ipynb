{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMirw4epACwb",
        "outputId": "6b9ffc9c-e3ee-4f08-b605-99e02a389d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext.vocab as vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove = vocab.GloVe(name='6B', dim=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb6KYRk9ALXF",
        "outputId": "eaa03d36-148a-416a-c64c-40a654675669"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.42MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:27<00:00, 14600.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of words and embeddings\n",
        "glove.vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiTitG4PAl5z",
        "outputId": "7aa7cddd-b256-4acb-c40c-6438086021a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400000, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the embedding vector\n",
        "def get_embedding_vector(word):\n",
        "  word_index = glove.stoi[word]\n",
        "  emb = glove.vectors[word_index]\n",
        "\n",
        "  return emb"
      ],
      "metadata": {
        "id": "wV5qZxg1cb80"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_embedding_vector('chess').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2F_ToSEc4P-",
        "outputId": "36051759-f698-4add-cb0f-763607966c14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_closest_words_from_word(word, max_n=5):\n",
        "  word_emb = get_embedding_vector(word)\n",
        "  distances = [(w, torch.dist(word_emb, get_embedding_vector(w)).cpu().item()) for w in glove.itos]\n",
        "  dist_sort_filt = sorted(distances, key=lambda x: x[1])[:max_n]\n",
        "\n",
        "  return dist_sort_filt"
      ],
      "metadata": {
        "id": "FQHsI-4Rc_2z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_closest_words_from_emb(word_emb, max_n=5):\n",
        "  distances = [(w, torch.dist(word_emb, get_embedding_vector(w)).cpu().item()) for w in glove.itos]\n",
        "  dist_sort_filt = sorted(distances, key=lambda x: x[1])[:max_n]\n",
        "\n",
        "  return dist_sort_filt"
      ],
      "metadata": {
        "id": "wDpA6dmwgnZ7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_closest_words_from_word('chess')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcvpYfdzel3B",
        "outputId": "d8637987-e33c-44d3-9c54-0ce3276af5ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chess', 0.0),\n",
              " ('backgammon', 4.379469394683838),\n",
              " ('grandmasters', 4.56368350982666),\n",
              " ('grandmaster', 4.613785743713379),\n",
              " ('scrabble', 4.677640438079834)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word analogies\n",
        "\n",
        "def get_word_analogy(word1, word2, word3, max_n=5):\n",
        "  # w1 - w2 + w3 --> w4\n",
        "  word1_emb = get_embedding_vector(word1)\n",
        "  word2_emb = get_embedding_vector(word2)\n",
        "  word3_emb = get_embedding_vector(word3)\n",
        "\n",
        "  word4_emb = word1_emb - word2_emb + word3_emb\n",
        "\n",
        "  analogy = get_closest_words_from_emb(word4_emb)\n",
        "\n",
        "  return analogy"
      ],
      "metadata": {
        "id": "NroRwWvqfW78"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_analogy('king', 'man', 'woman')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFEqNAX_hOKs",
        "outputId": "3e1f7379-04ee-477c-9f29-5d4c6a4b5875"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 3.364067792892456),\n",
              " ('queen', 4.081079006195068),\n",
              " ('monarch', 4.642907619476318),\n",
              " ('throne', 4.905500411987305),\n",
              " ('elizabeth', 4.921558856964111)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5v3YlWINhVFz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}